{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ba9908-a6a9-4555-b7e7-ba784b64cc25",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Cell 1: Install dependencies (WITHOUT flash-attn)\n",
    "!pip install torch==2.8.0 torchvision==0.23.0 --index-url https://download.pytorch.org/whl/cu128\n",
    "!pip install transformers pillow requests pdf2image poppler-utils tqdm accelerate pypdf\n",
    "!apt-get update && apt-get install -y poppler-utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed144dcb-340b-4d01-bc24-cb878c84438b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Cell 2: Verify GPU\n",
    "import torch\n",
    "print(f\"CUDA available: {torch.cuda.is_available()}\")\n",
    "print(f\"GPU: {torch.cuda.get_device_name(0)}\")\n",
    "print(f\"VRAM: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78561d55-9877-438d-8bb1-c830a547285c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Cell 2.5: Install system dependencies\n",
    "!sudo apt-get update -qq\n",
    "!sudo apt-get install -y poppler-utils\n",
    "\n",
    "# Verify installation\n",
    "!which pdfinfo\n",
    "!pdfinfo -v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "781749f6-7353-44c9-965b-c8694577c34a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this first to clear any lingering memory\n",
    "import torch, gc\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()\n",
    "print(f\"üßπ Cleared. Free memory: {(torch.cuda.get_device_properties(0).total_memory - torch.cuda.memory_allocated()) / 1e9:.2f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "557579c1-2e14-46dc-991a-355340acbf3c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check model cache\n",
    "!du -sh ~/.cache/huggingface/hub/models--TomoroAI--tomoro-colqwen3-embed-8b/\n",
    "!ls -lh ~/.cache/huggingface/hub/models--TomoroAI--tomoro-colqwen3-embed-8b/snapshots/*/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcab9984-2a50-41d0-8130-688fad2a7c7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import AutoModel, AutoProcessor\n",
    "from PIL import Image\n",
    "from pdf2image import convert_from_path\n",
    "from pathlib import Path\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import gc\n",
    "\n",
    "MODEL_ID = \"TomoroAI/tomoro-colqwen3-embed-8b\"\n",
    "DTYPE = torch.bfloat16\n",
    "DEVICE = \"cuda\"\n",
    "BATCH_SIZE = 2   # Reduced from 8\n",
    "DPI = 150        # Keep high quality for flowcharts\n",
    "\n",
    "print(\"üì¶ Loading model...\")\n",
    "processor = AutoProcessor.from_pretrained(\n",
    "    MODEL_ID, trust_remote_code=True, max_num_visual_tokens=1280\n",
    ")\n",
    "model = AutoModel.from_pretrained(\n",
    "    MODEL_ID,\n",
    "    dtype=DTYPE,\n",
    "    attn_implementation=\"sdpa\",\n",
    "    trust_remote_code=True,\n",
    "    device_map=DEVICE,\n",
    ").eval()\n",
    "\n",
    "print(\"‚úÖ Model loaded\")\n",
    "print(f\"üîß GPU Memory - Total: {torch.cuda.get_device_properties(0).total_memory / 1e9:.1f} GB\")\n",
    "print(f\"üîß After model load - Allocated: {torch.cuda.memory_allocated() / 1e9:.2f} GB\\n\")\n",
    "\n",
    "# Process PDFs\n",
    "docs_dir = Path(\"./\")\n",
    "pdf_files = [\"swm_2016.pdf\", \"urdpfi_vol1.pdf\", \"urdpfi_vol2.pdf\"]\n",
    "\n",
    "all_embeddings = []\n",
    "all_metadata = []\n",
    "\n",
    "for pdf_name in pdf_files:\n",
    "    pdf_path = docs_dir / pdf_name\n",
    "    \n",
    "    if not pdf_path.exists():\n",
    "        print(f\"‚ö†Ô∏è  Skipping {pdf_name} (not found)\")\n",
    "        continue\n",
    "    \n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"üìÑ Processing: {pdf_name}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # Convert PDF to images\n",
    "    print(\"  üñºÔ∏è  Converting to images...\")\n",
    "    images = convert_from_path(str(pdf_path), dpi=DPI)\n",
    "    print(f\"  ‚úÖ {len(images)} pages converted\")\n",
    "    \n",
    "    # Clear memory before embedding\n",
    "    gc.collect()\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "\n",
    "    # Embed in batches\n",
    "    print(f\"  üîÆ Embedding (batch_size={BATCH_SIZE})...\")\n",
    "    outputs = []\n",
    "    \n",
    "    for start in tqdm(range(0, len(images), BATCH_SIZE), desc=\"  Progress\"):\n",
    "        batch_imgs = images[start : start + BATCH_SIZE]\n",
    "        \n",
    "        # Process batch\n",
    "        features = processor.process_images(images=batch_imgs)\n",
    "        features = {k: v.to(DEVICE) if isinstance(v, torch.Tensor) else v \n",
    "                   for k, v in features.items()}\n",
    "        \n",
    "        # Generate embeddings\n",
    "        with torch.inference_mode():\n",
    "            out = model(**features)\n",
    "            vecs = out.embeddings.to(torch.bfloat16).cpu()\n",
    "        \n",
    "        outputs.extend(vecs)\n",
    "        \n",
    "        # CRITICAL: Clear memory after EACH batch\n",
    "        del features, out, batch_imgs\n",
    "        torch.cuda.empty_cache()\n",
    "    \n",
    "    # Store with metadata\n",
    "    for idx, emb in enumerate(outputs):\n",
    "        all_embeddings.append(emb)\n",
    "        all_metadata.append({\n",
    "            \"source\": pdf_name,\n",
    "            \"page\": idx + 1,\n",
    "            \"total_pages\": len(images)\n",
    "        })\n",
    "    \n",
    "    # Clear images from memory\n",
    "    del images, outputs\n",
    "    gc.collect()\n",
    "    \n",
    "    print(f\"  ‚úÖ Embedded {len(all_embeddings)} total pages so far\")\n",
    "    print(f\"  üîß GPU Memory - Allocated: {torch.cuda.memory_allocated() / 1e9:.2f} GB\\n\")\n",
    "\n",
    "# Save results\n",
    "print(f\"\\n{'='*60}\")\n",
    "print(\"üíæ Saving embeddings...\")\n",
    "print(f\"{'='*60}\")\n",
    "\n",
    "output_dir = Path(\"./embeddings_output\")\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "embeddings_tensor = torch.stack(all_embeddings)\n",
    "torch.save(embeddings_tensor, output_dir / \"embeddings.pt\")\n",
    "\n",
    "with open(output_dir / \"metadata.json\", \"w\") as f:\n",
    "    json.dump(all_metadata, f, indent=2)\n",
    "\n",
    "print(f\"\\n‚úÖ COMPLETE!\")\n",
    "print(f\"üìä Total pages embedded: {len(all_embeddings)}\")\n",
    "print(f\"üíæ Files saved to: {output_dir}\")\n",
    "print(f\"   - embeddings.pt ({embeddings_tensor.element_size() * embeddings_tensor.nelement() / 1e6:.1f} MB)\")\n",
    "print(f\"   - metadata.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25d18a7e-d281-46c2-bca2-05ff1a6e450a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick cell on Lightning before shutting down\n",
    "from pdf2image import convert_from_path\n",
    "from pathlib import Path\n",
    "\n",
    "output_dir = Path(\"./page_images\")\n",
    "output_dir.mkdir(exist_ok=True)\n",
    "\n",
    "docs_dir = Path(\"./\")\n",
    "for pdf_name in [\"swm_2016.pdf\", \"urdpfi_vol1.pdf\", \"urdpfi_vol2.pdf\"]:\n",
    "    images = convert_from_path(docs_dir / pdf_name, dpi=150)\n",
    "    for idx, img in enumerate(images):\n",
    "        img.save(output_dir / f\"{pdf_name.replace('.pdf', '')}__page_{idx+1:04d}.png\")\n",
    "\n",
    "# Then download the entire page_images/ folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc487e4c-3066-43c2-9100-1ebe8bbc65fa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
