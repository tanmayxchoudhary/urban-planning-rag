{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30561ca0-e1de-4691-a3da-ccf6e0999ff1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!pip install faiss-cpu google-genai python-dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a9bee6-8ca0-4baa-ad20-767e53467769",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "data_dir = Path(\"./data\")\n",
    "print(f\"Embeddings exist: {(data_dir / 'embeddings/embeddings.pt').exists()}\")\n",
    "print(f\"Metadata exists: {(data_dir / 'embeddings/metadata.json').exists()}\")\n",
    "print(f\"Images count: {len(list((data_dir / 'page_images').glob('*.png')))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb1af1d-dacc-4cbb-9342-b1d65bf1d834",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import faiss\n",
    "import numpy as np\n",
    "import json\n",
    "from pathlib import Path\n",
    "from google import genai\n",
    "from PIL import Image\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# Load environment\n",
    "load_dotenv()\n",
    "\n",
    "class UrbanPlanningRAG:\n",
    "    \"\"\"Complete RAG system with ColQwen + FAISS + Gemini\"\"\"\n",
    "    \n",
    "    def __init__(self, data_dir: str = \"./data\"):\n",
    "        self.data_dir = Path(data_dir)\n",
    "        self.embeddings_path = self.data_dir / \"embeddings\" / \"embeddings.pt\"\n",
    "        self.metadata_path = self.data_dir / \"embeddings\" / \"metadata.json\"\n",
    "        self.images_dir = self.data_dir / \"page_images\"\n",
    "        \n",
    "        print(\"=\" * 60)\n",
    "        print(\"üöÄ Initializing Urban Planning RAG System\")\n",
    "        print(\"=\" * 60)\n",
    "        \n",
    "        # Load embeddings and metadata\n",
    "        print(\"\\nüìÇ Loading embeddings...\")\n",
    "        self.embeddings_data = torch.load(self.embeddings_path, map_location='cpu')\n",
    "        \n",
    "        print(\"üìÇ Loading metadata...\")\n",
    "        with open(self.metadata_path, 'r') as f:\n",
    "            self.metadata = json.load(f)\n",
    "        \n",
    "        # Build FAISS index\n",
    "        print(\"üóÑÔ∏è  Building FAISS index...\")\n",
    "        self._build_faiss_index()\n",
    "        \n",
    "        # Load ColQwen for query encoding\n",
    "        print(\"üì¶ Loading ColQwen for query encoding...\")\n",
    "        self._load_query_encoder()\n",
    "        \n",
    "        # Initialize Gemini\n",
    "        print(\"ü§ñ Initializing Gemini VLM...\")\n",
    "        self._init_gemini()\n",
    "        \n",
    "        print(f\"\\n‚úÖ RAG system ready with {len(self.metadata)} pages indexed\")\n",
    "        print(\"=\" * 60)\n",
    "    \n",
    "    def _build_faiss_index(self):\n",
    "        \"\"\"Build FAISS index from embeddings\"\"\"\n",
    "        embeddings_list = []\n",
    "        \n",
    "        for idx in range(len(self.metadata)):\n",
    "            page_embedding = self.embeddings_data[idx].float()\n",
    "            avg_embedding = page_embedding.mean(dim=0).numpy()\n",
    "            embeddings_list.append(avg_embedding)\n",
    "        \n",
    "        embeddings_matrix = np.vstack(embeddings_list).astype('float32')\n",
    "        self.embedding_dim = embeddings_matrix.shape[1]\n",
    "        \n",
    "        # Create FAISS index\n",
    "        self.index = faiss.IndexFlatIP(self.embedding_dim)\n",
    "        faiss.normalize_L2(embeddings_matrix)\n",
    "        self.index.add(embeddings_matrix)\n",
    "        \n",
    "        print(f\"  ‚úÖ Indexed {self.index.ntotal} pages\")\n",
    "    \n",
    "    def _load_query_encoder(self):\n",
    "        \"\"\"Load ColQwen model for query encoding\"\"\"\n",
    "        from transformers import AutoModel, AutoProcessor\n",
    "        \n",
    "        MODEL_ID = \"TomoroAI/tomoro-colqwen3-embed-8b\"\n",
    "        \n",
    "        self.processor = AutoProcessor.from_pretrained(\n",
    "            MODEL_ID,\n",
    "            trust_remote_code=True,\n",
    "            max_num_visual_tokens=1280,\n",
    "        )\n",
    "        self.model = AutoModel.from_pretrained(\n",
    "            MODEL_ID,\n",
    "            torch_dtype=torch.bfloat16,\n",
    "            attn_implementation=\"sdpa\",\n",
    "            trust_remote_code=True,\n",
    "            device_map=\"cpu\",                       #cpu/cuda\n",
    "        ).eval()\n",
    "        \n",
    "        print(f\"  ‚úÖ ColQwen loaded\")\n",
    "    \n",
    "    def _init_gemini(self):\n",
    "        \"\"\"Initialize Gemini client\"\"\"\n",
    "        api_key = os.getenv('GEMINI_API_KEY')\n",
    "        if not api_key:\n",
    "            raise ValueError(\"GEMINI_API_KEY not found in .env\")\n",
    "        \n",
    "        self.gemini_client = genai.Client(api_key=api_key)\n",
    "        print(f\"  ‚úÖ Gemini client ready\")\n",
    "    \n",
    "    def encode_query(self, query: str):\n",
    "        \"\"\"Encode text query using ColQwen\"\"\"\n",
    "        features = self.processor.process_texts([query])\n",
    "        features = {k: v.to(\"cpu\") if isinstance(v, torch.Tensor) else v #cpu/cuda\n",
    "                   for k, v in features.items()}\n",
    "        \n",
    "        with torch.inference_mode():\n",
    "            out = self.model(**features)\n",
    "            query_vec = out.embeddings[0].float().mean(dim=0).cpu().numpy()\n",
    "        \n",
    "        return query_vec\n",
    "    \n",
    "    def retrieve(self, query: str, top_k: int = 3):\n",
    "        \"\"\"Retrieve top-k relevant pages\"\"\"\n",
    "        print(f\"\\nüîç Query: '{query}'\")\n",
    "        print(f\"üìä Retrieving top {top_k} pages...\")\n",
    "        \n",
    "        # Encode query\n",
    "        query_vec = self.encode_query(query)\n",
    "        query_norm = query_vec.reshape(1, -1).astype('float32')\n",
    "        faiss.normalize_L2(query_norm)\n",
    "        \n",
    "        # Search\n",
    "        distances, indices = self.index.search(query_norm, top_k)\n",
    "        \n",
    "        # Format results\n",
    "        results = []\n",
    "        for i in range(len(indices[0])):\n",
    "            idx = indices[0][i]\n",
    "            if idx < len(self.metadata):\n",
    "                item = self.metadata[idx]\n",
    "                source_name = item['source'].replace('.pdf', '').replace(' ', '_').lower()\n",
    "                image_filename = f\"{source_name}__page_{item['page']:04d}.png\"\n",
    "                \n",
    "                results.append({\n",
    "                    'source': item['source'],\n",
    "                    'page': item['page'],\n",
    "                    'total_pages': item['total_pages'],\n",
    "                    'image_path': str(self.images_dir / image_filename),\n",
    "                    'similarity': float(distances[0][i])\n",
    "                })\n",
    "        \n",
    "        return results\n",
    "    \n",
    "    def answer_query(self, query: str, top_k: int = 3):\n",
    "        \"\"\"Complete RAG: Retrieve + Generate answer\"\"\"\n",
    "        \n",
    "        # Retrieve relevant pages\n",
    "        retrieved = self.retrieve(query, top_k=top_k)\n",
    "        \n",
    "        print(f\"\\nüìã Retrieved pages:\")\n",
    "        for i, r in enumerate(retrieved, 1):\n",
    "            print(f\"  {i}. {r['source']} - Page {r['page']} (similarity: {r['similarity']:.3f})\")\n",
    "        \n",
    "        # Load page images\n",
    "        print(f\"\\nüñºÔ∏è  Loading page images...\")\n",
    "        page_images = []\n",
    "        for r in retrieved:\n",
    "            img_path = Path(r['image_path'])\n",
    "            if img_path.exists():\n",
    "                page_images.append(Image.open(img_path))\n",
    "        \n",
    "        if not page_images:\n",
    "            return \"‚ùå No valid page images found\"\n",
    "        \n",
    "        # Generate answer with Gemini\n",
    "        print(f\"ü§ñ Generating answer with Gemini...\")\n",
    "        \n",
    "        prompt = f\"\"\"You are an expert in Indian urban planning regulations. \n",
    "\n",
    "Question: {query}\n",
    "\n",
    "I've provided {len(page_images)} relevant pages from planning documents. Please:\n",
    "1. Answer the question based on the provided pages\n",
    "2. Cite which page number contains the information\n",
    "3. If the information is not in the provided pages, say so\n",
    "\n",
    "Be concise and specific.\"\"\"\n",
    "\n",
    "        response = self.gemini_client.models.generate_content(\n",
    "            model='gemini-3-flash-preview',\n",
    "            contents=[prompt] + page_images\n",
    "        )\n",
    "        \n",
    "        return response.text\n",
    "\n",
    "# Initialize RAG system\n",
    "rag = UrbanPlanningRAG()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8157884-2a61-4abb-a9e3-49ec98de539e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test it!\n",
    "answer = rag.answer_query(\"what are indicators of good governace\", top_k=3)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üìù ANSWER:\")\n",
    "print(\"=\" * 60)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c2e1afd-dca9-49a1-82cd-b365e9039a94",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
